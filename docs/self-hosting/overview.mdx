---
title: Overview
description: Learn how to self-host Allama on your own infrastructure.
---

Self-hosting Allama lets you retain data on your own infrastructure and network.
Choose from a number of deployment options listed below to get started.

<CardGroup cols={2}>
  <Card title="Docker Compose" icon="docker" href="/self-hosting/deployment-options/docker-compose">
    Install Allama locally or inside a VM (e.g. AWS EC2) using our Docker Compose template.
  </Card>
  <Card title="AWS ECS Fargate" icon="aws" href="/self-hosting/deployment-options/aws-ecs">
    Use Terraform to deploy Allama into ECS Fargate.
  </Card>
</CardGroup>

Interested in using open source LLMs (e.g. `llama3.2`) in Allama's AI actions?
Check out our guide on deploying [self-hosted LLMs](/self-hosting/llms) with Allama's Ollama Docker Compose extension.
